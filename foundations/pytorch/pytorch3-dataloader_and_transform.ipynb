{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de3905f-2107-4382-a5dc-8de3647348f2",
   "metadata": {},
   "source": [
    "# Learning Data Loader on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944be501-4007-4f05-beba-cc280cdf23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from sklearn.datasets import load_wine\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c485ac8-5c39-455b-93c4-6ad1a30234a9",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "* `one epochs` : one forward and backward calculations for ALL training samples\n",
    "* `batch size` : number of samples on that passed to each batches\n",
    "* `iteration` : the number of forward and backward calculation done on each batch samples for one epochs\n",
    "\n",
    "**Example :** the number of All training data is 100 with 4 batch size. then the total number of iterations is 100/4 = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693bd8cf-8f94-4048-848e-bef9067a33bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# the scheme of data loader looks like this:\n",
    "\n",
    "\"\"\"\n",
    "# Training loop\n",
    "for e in range(number_of_epochs):\n",
    "    for i in range(number_of_batches):\n",
    "        # Execution\n",
    "        x_batches, y_batches = ...\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b8dd4-39ad-48d7-826a-bc763e9db66e",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c732dcb-de23-4315-81a0-b443b768edd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14.23,    1.71,    2.43, ...,    3.92, 1065.  ,    0.  ],\n",
       "       [  13.2 ,    1.78,    2.14, ...,    3.4 , 1050.  ,    0.  ],\n",
       "       [  13.16,    2.36,    2.67, ...,    3.17, 1185.  ,    0.  ],\n",
       "       ...,\n",
       "       [  13.27,    4.28,    2.26, ...,    1.56,  835.  ,    2.  ],\n",
       "       [  13.17,    2.59,    2.37, ...,    1.62,  840.  ,    2.  ],\n",
       "       [  14.13,    4.1 ,    2.74, ...,    1.6 ,  560.  ,    2.  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "X, y = load_wine(return_X_y=True)\n",
    "data = np.concatenate([X, y.reshape(-1,1)], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed90397-2899-4137-ae11-3863aa501759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15046f27-9cd9-4078-8f72-5a06775a6aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498a1e01-0a6b-4774-a281-35747f3ed56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets class\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    # initialize class \n",
    "    def __init__(self):\n",
    "        # initialize all dataset class\n",
    "        super().__init__()\n",
    "        \n",
    "        # load dataset\n",
    "        X, y = load_wine(return_X_y=True)\n",
    "\n",
    "        # convert it into torch tensor and save properties\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.reshape(-1,1).astype(np.float32))\n",
    "        self.n_samples = len(X)\n",
    "\n",
    "    # make it can be indexed\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    # make it can return length\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f9b403-b222-438f-88db-df8ea4b5ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wine dataset\n",
    "data = WineDataset()\n",
    "\n",
    "# Create Data Loader\n",
    "dataloader = DataLoader(data,\n",
    "                        batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733f6c5c-08d5-408d-8be7-0a516af5c56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data of index 1\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f608cc-ea28-46e6-887d-512cf6b5315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Execution will produce an Error of: 'DataLoader' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "# try to index on dataloader object\n",
    "try:\n",
    "    dataloader[0]\n",
    "except TypeError:\n",
    "    print(\"This Execution will produce an Error of: 'DataLoader' object is not subscriptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6409ed0d-b600-497b-bf29-0f97d9394c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of doing directly from dataloader object\n",
    "# we can utilize iter() built-in function from python to iterate\n",
    "# and being able to subscript the dataloader obejct\n",
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36bf8102-79d9-4ce1-b5b7-3132434bb24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =  tensor([[1.4120e+01, 1.4800e+00, 2.3200e+00, 1.6800e+01, 9.5000e+01, 2.2000e+00,\n",
      "         2.4300e+00, 2.6000e-01, 1.5700e+00, 5.0000e+00, 1.1700e+00, 2.8200e+00,\n",
      "         1.2800e+03],\n",
      "        [1.1840e+01, 2.8900e+00, 2.2300e+00, 1.8000e+01, 1.1200e+02, 1.7200e+00,\n",
      "         1.3200e+00, 4.3000e-01, 9.5000e-01, 2.6500e+00, 9.6000e-01, 2.5200e+00,\n",
      "         5.0000e+02],\n",
      "        [1.2880e+01, 2.9900e+00, 2.4000e+00, 2.0000e+01, 1.0400e+02, 1.3000e+00,\n",
      "         1.2200e+00, 2.4000e-01, 8.3000e-01, 5.4000e+00, 7.4000e-01, 1.4200e+00,\n",
      "         5.3000e+02],\n",
      "        [1.2370e+01, 1.1700e+00, 1.9200e+00, 1.9600e+01, 7.8000e+01, 2.1100e+00,\n",
      "         2.0000e+00, 2.7000e-01, 1.0400e+00, 4.6800e+00, 1.1200e+00, 3.4800e+00,\n",
      "         5.1000e+02]])\n",
      "y =  tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "\n",
      "\n",
      "X =  tensor([[1.3160e+01, 3.5700e+00, 2.1500e+00, 2.1000e+01, 1.0200e+02, 1.5000e+00,\n",
      "         5.5000e-01, 4.3000e-01, 1.3000e+00, 4.0000e+00, 6.0000e-01, 1.6800e+00,\n",
      "         8.3000e+02],\n",
      "        [1.4130e+01, 4.1000e+00, 2.7400e+00, 2.4500e+01, 9.6000e+01, 2.0500e+00,\n",
      "         7.6000e-01, 5.6000e-01, 1.3500e+00, 9.2000e+00, 6.1000e-01, 1.6000e+00,\n",
      "         5.6000e+02],\n",
      "        [1.4190e+01, 1.5900e+00, 2.4800e+00, 1.6500e+01, 1.0800e+02, 3.3000e+00,\n",
      "         3.9300e+00, 3.2000e-01, 1.8600e+00, 8.7000e+00, 1.2300e+00, 2.8200e+00,\n",
      "         1.6800e+03],\n",
      "        [1.2080e+01, 1.8300e+00, 2.3200e+00, 1.8500e+01, 8.1000e+01, 1.6000e+00,\n",
      "         1.5000e+00, 5.2000e-01, 1.6400e+00, 2.4000e+00, 1.0800e+00, 2.2700e+00,\n",
      "         4.8000e+02]])\n",
      "y =  tensor([[2.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "\n",
      "\n",
      "X =  tensor([[1.2510e+01, 1.7300e+00, 1.9800e+00, 2.0500e+01, 8.5000e+01, 2.2000e+00,\n",
      "         1.9200e+00, 3.2000e-01, 1.4800e+00, 2.9400e+00, 1.0400e+00, 3.5700e+00,\n",
      "         6.7200e+02],\n",
      "        [1.2290e+01, 2.8300e+00, 2.2200e+00, 1.8000e+01, 8.8000e+01, 2.4500e+00,\n",
      "         2.2500e+00, 2.5000e-01, 1.9900e+00, 2.1500e+00, 1.1500e+00, 3.3000e+00,\n",
      "         2.9000e+02],\n",
      "        [1.3270e+01, 4.2800e+00, 2.2600e+00, 2.0000e+01, 1.2000e+02, 1.5900e+00,\n",
      "         6.9000e-01, 4.3000e-01, 1.3500e+00, 1.0200e+01, 5.9000e-01, 1.5600e+00,\n",
      "         8.3500e+02],\n",
      "        [1.2470e+01, 1.5200e+00, 2.2000e+00, 1.9000e+01, 1.6200e+02, 2.5000e+00,\n",
      "         2.2700e+00, 3.2000e-01, 3.2800e+00, 2.6000e+00, 1.1600e+00, 2.6300e+00,\n",
      "         9.3700e+02]])\n",
      "y =  tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itersample = 0\n",
    "for x,y in dataiter:\n",
    "    print(\"X = \", x)\n",
    "    print(\"y = \", y)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # break the for loop if it has return the first 3 item from dataiter\n",
    "    itersample +=1\n",
    "    if itersample == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5c921-9211-4af6-8a28-447a8c643e56",
   "metadata": {},
   "source": [
    "**Conclution:**\n",
    "\n",
    "it is different when we index using data loader. on each iterate object is actually a tuple/list consisting of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc967c3f-e22a-499d-81d7-86e3962524ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2 - step: 5/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 10/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 15/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 20/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 25/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 30/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 35/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 40/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 1/2 - step: 45/45.0 - input_shape: torch.Size([2, 13]) - label_shape: torch.Size([2, 1])\n",
      "epoch: 2/2 - step: 5/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 10/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 15/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 20/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 25/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 30/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 35/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 40/45.0 - input_shape: torch.Size([4, 13]) - label_shape: torch.Size([4, 1])\n",
      "epoch: 2/2 - step: 45/45.0 - input_shape: torch.Size([2, 13]) - label_shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 2\n",
    "n_iters = np.ceil(len(data)/4)\n",
    "\n",
    "# print the result every n step\n",
    "print_step = 5\n",
    "for epoch in range(n_epoch):\n",
    "    for idx, (input_tensors, labels) in enumerate(dataloader):\n",
    "        # this is the execution process skipped for forward, backward, and gradients update calculations\n",
    "\n",
    "        # print the results:\n",
    "        if (idx+1) % print_step == 0:\n",
    "            print(f\"epoch: {(epoch+1)}/{(n_epoch)} - step: {idx+1}/{n_iters} - input_shape: {input_tensors.shape} - label_shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e2d64-3686-41a4-8c48-4ff396d9bcf2",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "we can use transform from pytorch to be combined with out dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "032b2ee9-2497-4182-88c0-5381e6798d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified WineDataset Class\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    # initialize class \n",
    "    def __init__(self, transform = None):\n",
    "        # initialize all dataset class\n",
    "        super().__init__()\n",
    "        \n",
    "        # load dataset\n",
    "        self.X, self.y = load_wine(return_X_y=True)\n",
    "        self.n_samples = len(X)\n",
    "        self.transform = transform\n",
    "\n",
    "    # make it can be indexed\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.X[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    # make it can return length\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create custom torch transformer\n",
    "class ToTensor:\n",
    "    # create call properties\n",
    "    def __call__(self, sample):\n",
    "        X, y = sample\n",
    "        X = torch.from_numpy(X.astype(np.float32))\n",
    "        y = torch.from_numpy(y.reshape(-1,1).astype(np.float32))\n",
    "        return X, y\n",
    "\n",
    "\n",
    "# create another torch transformer\n",
    "class MulTransform:\n",
    "    # create call properties\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        X, y = sample\n",
    "        X *= self.factor\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "154ffd36-9797-42af-8d33-a066bbbc43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wine dataset\n",
    "data = WineDataset(transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40fc52dc-42d5-46c7-9f2d-6b34dfeb0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return sample type : <class 'tuple'>\n",
      "\n",
      "dataset overview: \n",
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([[0.]]))\n",
      "\n",
      "dataset type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# look at dataset\n",
    "print(f\"return sample type : {type(data[0])}\\n\")\n",
    "print(f\"dataset overview: \\n{data[0]}\\n\")\n",
    "print(f\"dataset type: {type(data[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ee320ac-f4b7-47df-acdc-687f4b83eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using composed transform\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2d7e6dc-3c1c-4b67-8087-fe58783733f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create compose dataset\n",
    "composed = Compose([ToTensor(), MulTransform(10)])\n",
    "\n",
    "# load wine dataset\n",
    "data = WineDataset(transform = composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1381b08-26a8-4532-8e2a-2c2f9dab3696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return sample type : <class 'tuple'>\n",
      "\n",
      "dataset overview: \n",
      "(tensor([1.4230e+02, 1.7100e+01, 2.4300e+01, 1.5600e+02, 1.2700e+03, 2.8000e+01,\n",
      "        3.0600e+01, 2.8000e+00, 2.2900e+01, 5.6400e+01, 1.0400e+01, 3.9200e+01,\n",
      "        1.0650e+04]), tensor([[0.]]))\n",
      "\n",
      "dataset type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# look at dataset\n",
    "print(f\"return sample type : {type(data[0])}\\n\")\n",
    "print(f\"dataset overview: \\n{data[0]}\\n\")\n",
    "print(f\"dataset type: {type(data[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f4a2d-c6c0-4d8f-a0df-11111c4c2f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
